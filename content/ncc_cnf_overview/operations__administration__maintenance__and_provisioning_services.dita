<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE concept PUBLIC "-//OASIS//DTD DITA Concept//EN" "concept.dtd">
<concept id="operations__administration__maintenance__and_provisioning_services">
    <title>Operations, administration, maintenance and provisioning services</title>
    <conbody>
        <p>This section describes the operations, administration, maintenance and provisioning
            services of NCC CNF.</p>
        <section id="section_ltq_htm_rlb">
            <title>Command-line tools</title>
            <p>NCC command-line tools run on the <i>admincli</i> pod. Users run a
                <codeph>kubectl</codeph> command to gain access to this pod for using the NCC 
                tools.</p>
        </section>
        <section id="section_zvp_hsc_llb">
            <title>Logs, alarms and metrics</title>
            <p>NCC logs are written to stdout. They are processed and directed by Fluentd. Users can
                search, filter and browse the logs using standard tools including Elasticsearch and
                Kibana. </p>
            <p>Metrics are written to Prometheus using the Java client APIs. In deployments where
                the operator is not providing the telemetry infrastructure, NCC leverages the
                Gen3GPPXML tool to retrieve metrics data from Prometheus, writes it to XML files in
                a persistent volume, and makes them available to northbound OSS systems (such as
                NetAct) to retrieve using SFTP.</p>
            <p>NCC alarms are written to stdout and are processed/directed by Fluentd. However, some
                customers consume the alarms from stdout using their own Fluentd and alarm handling
                components (similar to CALM) and are responsible for sending alarms to northbound
                OSS systems (such as NetAct).</p>
            <p>For the initial version, NCC includes BTEL in its delivery. Metrics, alarms, and logs
                are forwarded to the operator's infrastructure using a single VES stream. However,
                NCC keeps its own copy of its alarms/metric/logs, for troubleshooting. </p>
        </section>
        <section id="section_awp_hsc_llb">
            <title>Tracing to aid troubleshooting</title>
            <p>NCC supports OpenTracing throughout its various call flows, for creating sampled
                tracing data that can be collected and displayed by Jaeger. The initial version
                focuses on end-to-end tracing of incoming 4G Diameter messages (and responses), 5G
                HTTP/2 messages (and responses), and provisioning flows through SM and the ME
                provisioning. Additional flows have OpenTracing support in future versions.</p>
            <p>Jaeger can then be used for collecting and presenting the tracing data, from the
                OpenTracing calls. Sampling policies can be configured, such as sampling one message
                out of 1,000, or two messages per second, etc. Jaeger displays the latency of the
                total end-to-end flow, as well as for each span within the flow.</p>
            <p>Kiali can also be used to present some high level views of that data. </p>
        </section>
        <section id="section_u2c_jsc_llb">
            <title>System monitoring</title>
            <p>Individual instances of NCC pods are monitored with the standard mechanisms in
                Kubernetes, using liveness and readiness probes. As instances fail, Kubernetes spins
                up a new replacement, within the configured parameters for minimum and maximum
                number of instances, as well as considering the autoscaling parameters.</p>
            <p>NCC has an additional layer of monitoring functionality to manage composite states at
                the CNF level. For example, if the number of charging pods falls below a minimum
                threshold, then that overall service is considered OOS and then, since it is a vital
                service, the entire NCC CNF is considered OOS at that time. The network heartbeats
                includes this OOS status which allows traffic to be site-routed to the mate NCC ME.
                In addition, this newly OOS NCC ME must turn off its incoming traffic. This is done
                for Diameter by invoking an interface in the IOHD. </p>
        </section>
        <section id="section_it4_ksc_llb">
            <title>Provisioning</title>
            <p>NCC CNF subscribers/devices are provisioned through the SM. This can be a northbound
                provisioning system using the SM native REST APIs, or that system could use a set of
                custom APIs (typically SOAP or REST) provided by a custom HLAPI microservice
                provided by the Services team. This HLAPI microservice on the SM takes the
                customer-specific API in on one side, and invokes the SM standard REST APIs on the
                other side.</p>
            <p>SM selects a home ME for new subscribers/devices, if one is not already selected by
                the operator in the request. SM selection is based on least loaded ME, unless that
                new device is part of an existing group account, in which case that device is homed
                on the same ME as it peer group members. SM then sends the provisioning update to
                the home ME (the backup ME gets updated by virtue of XDR data replication). It goes
                to the Provisioning pod on the ME, where subscriber records are created in the DB.
                SM maintains an index mapping of where all subscribers / devices are homed, but does
                not keep a copy of the actual detailed records. Those are kept only on the ME.</p>
            <p>The provisioning service is horizontally scalable, including the SM application and
                the ME provisioning pod.</p>
        </section>
        <section id="section_k35_psc_llb">
            <title>CDR</title>
            <p>NCC CNF leverages microservices from Nokia Data Refinery (DR) to provide the NCC CDR
                handling and mediation features, creating CDR files that can be retrieved by
                external systems using SFTP. DR provides the flexibility and configurability that
                NCC customers require relative to CDR handling.</p>
            <p>NCC applications create CDR input content and enqueues it in Kafka for consumption by
                the CDR microservice. Kafka enables robust queuing and failure handling to ensure
                that CDR content is not lost, even in the midst of various failure scenarios.</p>
            <p>To process CDRs received over Kafka, Data Refinery uses three pod types for the DR
                streams. Each pod type is used for a specific DR stream. The first pod type is used
                for collecting data from Kafka (Kafka input stream). The second pod type is used for
                transforming data into required format (Business logic stream). The third pod type
                is used for creating the actual CDR files (Output stream). Each pod type is
                separately scalable, and N number of these pods provide horizontal scalability.
                Redis DB is used as a temporary storage between the DR streams.</p>
            <p>The Kafka input stream and the Business logic stream each have one node, whereas the
                Output stream has three nodes: collector node, ASN.1 encoder node and distributor
                node.  Currently the interface between the nodes in the Output stream is file-based.
                The goal is to replace it with a cloud-native interface. However, if the file-based
                interface is still used, the nodes in the Output stream must run in a single
                container to continue to use the file-based interface. In addition to stream
                processing, every pod runs a Node Manager that manages DR nodes in a DR stream,
                while Kubernetes manages the set of pods.</p>
            <p>DR provides a UI to manage the configuration parameters among other things by
                directly managing data that is stored in Redis. The SM UI includes a cut-through to
                the ME DR UI to configure the CDR stream processing. The UI includes only the subset
                necessary for online CDR processing, directly managing data in Redis. That portion
                of the DR UI is a foundation for expanded functionality as required by other
                features in Convergent Charging. The DR UI container uses a singleton pod. Given
                that the UI is lightly used, it is sufficient to have a brief gap in availability if
                Kubernetes has to replace the pod, including for a software update.</p>
            <p>The following figure shows how CDRs are processed in NCC CNF.</p>
            <fig id="fig_ajr_ykz_cmb">
                <title>CDR processing</title>
                <image placement="break" href="../images/cnf_overview_CDR-processing.GIF" scale="30"
                    align="center" id="image_bjr_ykz_cmb"/>
            </fig>
        </section>
    </conbody>
</concept>
