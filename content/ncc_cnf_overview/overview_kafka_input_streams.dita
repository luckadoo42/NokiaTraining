<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE topic
  PUBLIC "-//OASIS//DTD DITA Topic//EN" "topic.dtd">
<topic id="topicID3">
        <title>Kafka input stream</title>
        <body>
            <p>The different components within NCC generate EDRs and CDRs in NCC generic format and
            push them to an Apache Kafka topic. Kafka input stream collects the Kafka messages.</p>
            <p>The Kafka input stream, consisting of a standalone CG Kafka Node, polls messages from
            the egress topic, decodes and converts them to Data Refinery internal format without
            modifying the actual data, and writes them securely in the database, together with a
            session timeout for every record. After completing the handling of all polled records,
            the node performs a commit to Apache Kafka.</p>
            <p>After collecting a defined number of received records, CG Kafka Node creates a batch
                referring to the received records and stores the batch information into the
                database, allowing the Business logic stream to continue processing the records.</p>
            <fig id = "kafka">
                <title>Example of Kafka input stream</title>
            
            <image href="../images/sps_cfg_kafka.png" placement="break" height="2in"/>
            </fig>
            
            
            
            
            
            
            
            
            
            
            
            
        </body>
    </topic>
